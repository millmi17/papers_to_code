{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is going over and trying to recreate the model used the paper LIPNET: END-TO-END SENTENCE-LEVEL LIPREADING. this notebook was also inspired by Nicholas Renotte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T02:40:14.336977Z",
     "iopub.status.busy": "2023-02-18T02:40:14.336565Z",
     "iopub.status.idle": "2023-02-18T02:40:14.342126Z",
     "shell.execute_reply": "2023-02-18T02:40:14.341146Z",
     "shell.execute_reply.started": "2023-02-18T02:40:14.336941Z"
    }
   },
   "source": [
    "## in this we are only using one speaker in the grid data set. This will work for more speakers, but the time to train the model would take too long. This already took 6 min an epoch using a gpu on kaggle for only data for one speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T02:50:11.001798Z",
     "iopub.status.busy": "2023-02-18T02:50:11.001323Z",
     "iopub.status.idle": "2023-02-18T02:50:16.181635Z",
     "shell.execute_reply": "2023-02-18T02:50:16.180378Z",
     "shell.execute_reply.started": "2023-02-18T02:50:11.001753Z"
    }
   },
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "from tensorflow.nn import ctc_loss\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "import cv2\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Input,Conv3D, Dense, Dropout, Bidirectional, MaxPool3D, Activation, Reshape, BatchNormalization,GRU, TimeDistributed, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T02:50:16.184592Z",
     "iopub.status.busy": "2023-02-18T02:50:16.183917Z",
     "iopub.status.idle": "2023-02-18T02:50:16.195234Z",
     "shell.execute_reply": "2023-02-18T02:50:16.192265Z",
     "shell.execute_reply.started": "2023-02-18T02:50:16.184554Z"
    }
   },
   "outputs": [],
   "source": [
    "# this function takes a video and loads the images. It also crops around the lips with a set range of pixels\n",
    "# in the paper they use a lip detector to extract the lips. This is something that isn't implemented in this notebook\n",
    "    outputframes = []\n",
    "    video = cv2.VideoCapture(path)\n",
    "    countframes = video.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    for i in range(int(countframes)):\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, 1)\n",
    "        ret, frame = video.read()\n",
    "        frame = tf.image.rgb_to_grayscale(frame)\n",
    "\n",
    "        outputframes.append(tf.image.per_image_standardization(frame[190:236,80:220,:]))\n",
    "    return outputframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T02:50:16.197241Z",
     "iopub.status.busy": "2023-02-18T02:50:16.196752Z",
     "iopub.status.idle": "2023-02-18T02:50:16.210156Z",
     "shell.execute_reply": "2023-02-18T02:50:16.209189Z",
     "shell.execute_reply.started": "2023-02-18T02:50:16.197182Z"
    }
   },
   "outputs": [],
   "source": [
    "# creating the vocabulary\n",
    "vocab = [x for x in \"abcdefghijklmnopqrstuvwxyz'?!123456789 \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T02:50:16.213134Z",
     "iopub.status.busy": "2023-02-18T02:50:16.212785Z",
     "iopub.status.idle": "2023-02-18T02:50:18.974982Z",
     "shell.execute_reply": "2023-02-18T02:50:18.974052Z",
     "shell.execute_reply.started": "2023-02-18T02:50:16.213101Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-18 02:50:16.304196: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-18 02:50:16.400626: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-18 02:50:16.401414: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-18 02:50:16.403000: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-18 02:50:16.403324: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-18 02:50:16.403998: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-18 02:50:16.404701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-18 02:50:18.590957: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-18 02:50:18.591811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-18 02:50:18.592464: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-18 02:50:18.593038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "# these are creating a way to transform a charcter to a number and number to letter\n",
    "characternum = tf.keras.layers.StringLookup(vocabulary = vocab,oov_token=\"\")\n",
    "numcharacter = tf.keras.layers.StringLookup(vocabulary = vocab,oov_token=\"\",invert = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T02:50:18.977067Z",
     "iopub.status.busy": "2023-02-18T02:50:18.976630Z",
     "iopub.status.idle": "2023-02-18T02:50:18.983832Z",
     "shell.execute_reply": "2023-02-18T02:50:18.982549Z",
     "shell.execute_reply.started": "2023-02-18T02:50:18.977028Z"
    }
   },
   "outputs": [],
   "source": [
    "# this is loading the aligned labels for what the speaker is saying\n",
    "# we get rid of the parts for silence\n",
    "def load_align(path):\n",
    "    #print(path)\n",
    "    with open(path, 'r') as f: \n",
    "        lines = f.readlines() \n",
    "    sentence = []\n",
    "    \n",
    "    for line in lines:\n",
    "        L =line.split()[2]\n",
    "        if L == 'sil':\n",
    "            continue\n",
    "        else:\n",
    "            if len(sentence)>1:\n",
    "                sentence.append(' ')\n",
    "            for j in L:\n",
    "                sentence.append(j)\n",
    "    return characternum(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T02:50:18.986390Z",
     "iopub.status.busy": "2023-02-18T02:50:18.985566Z",
     "iopub.status.idle": "2023-02-18T02:50:18.997107Z",
     "shell.execute_reply": "2023-02-18T02:50:18.996257Z",
     "shell.execute_reply.started": "2023-02-18T02:50:18.986299Z"
    }
   },
   "outputs": [],
   "source": [
    "# takes in video file name and ruetruns the frames and the alignments of words\n",
    "def load(path):\n",
    "    \n",
    "    finalpath =bytes.decode(path.numpy())\n",
    "   \n",
    "    filename = finalpath.split('/')[-1]\n",
    "    filename = filename.split('.')[0]\n",
    "    \n",
    "    framepath = os.path.join('/kaggle','input','grid-1-speaker','s4.mpg_vcd','s4',finalpath)\n",
    "    alignpath = os.path.join('/kaggle','input','grid-1-speaker','s4','align',filename+'.align')\n",
    "    frames = load_frames(framepath)\n",
    "    align = load_align(alignpath)\n",
    "    return frames, align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T02:50:18.999021Z",
     "iopub.status.busy": "2023-02-18T02:50:18.998622Z",
     "iopub.status.idle": "2023-02-18T02:50:19.008271Z",
     "shell.execute_reply": "2023-02-18T02:50:19.007329Z",
     "shell.execute_reply.started": "2023-02-18T02:50:18.998988Z"
    }
   },
   "outputs": [],
   "source": [
    "# this is needed to create the load function to work with tensorflow\n",
    "def final_function(path:str):\n",
    "    return tf.py_function(func=load, inp=[path], Tout=(tf.float32,tf.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T02:50:19.010236Z",
     "iopub.status.busy": "2023-02-18T02:50:19.009866Z",
     "iopub.status.idle": "2023-02-18T02:50:19.659928Z",
     "shell.execute_reply": "2023-02-18T02:50:19.658960Z",
     "shell.execute_reply.started": "2023-02-18T02:50:19.010188Z"
    }
   },
   "outputs": [],
   "source": [
    "# this takes the data and shuffles, then runs our load function\n",
    "# then makes a batch of size 2 and prefetchs some data for faster training.\n",
    "# saving 450 videos for training and the rest for testing\n",
    "data = tf.data.Dataset.list_files('/kaggle/input/grid-1-speaker/s4.mpg_vcd/s4/*.mpg', shuffle=None, seed=42)\n",
    "data = data.shuffle(500, reshuffle_each_iteration=False)\n",
    "data = data.map(final_function)\n",
    "data = data.padded_batch(2, padded_shapes=([75,None,None,None],[40]))\n",
    "data = data.prefetch(tf.data.AUTOTUNE)\n",
    "# Added for split \n",
    "train = data.take(450)\n",
    "test = data.skip(450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T02:50:19.661580Z",
     "iopub.status.busy": "2023-02-18T02:50:19.661237Z",
     "iopub.status.idle": "2023-02-18T02:50:21.698130Z",
     "shell.execute_reply": "2023-02-18T02:50:21.697225Z",
     "shell.execute_reply.started": "2023-02-18T02:50:19.661546Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-18 02:50:19.689577: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 75, 46, 140, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames, alignments = data.as_numpy_iterator().next()\n",
    "frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T02:50:21.701567Z",
     "iopub.status.busy": "2023-02-18T02:50:21.701236Z",
     "iopub.status.idle": "2023-02-18T02:50:21.708339Z",
     "shell.execute_reply": "2023-02-18T02:50:21.707399Z",
     "shell.execute_reply.started": "2023-02-18T02:50:21.701540Z"
    }
   },
   "outputs": [],
   "source": [
    "# this is for the ctc loss. This code was copied from an example on the tensorflow website.\n",
    "# this loss is needed since our model will predict characters from our vocab for \n",
    "# each of the 75 frames. but the real alignments don't have 75 characters\n",
    "# thus this loss deals with this difference\n",
    "def CTCLoss(y_true, y_pred):\n",
    "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "\n",
    "    loss = tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T02:50:21.710722Z",
     "iopub.status.busy": "2023-02-18T02:50:21.709957Z",
     "iopub.status.idle": "2023-02-18T02:50:22.850036Z",
     "shell.execute_reply": "2023-02-18T02:50:22.849003Z",
     "shell.execute_reply.started": "2023-02-18T02:50:21.710687Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_9 (Conv3D)            (None, 75, 46, 140, 32)   832       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 75, 46, 140, 32)   0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_9 (MaxPooling3 (None, 75, 23, 70, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_10 (Conv3D)           (None, 75, 23, 70, 64)    51264     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 75, 23, 70, 64)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_10 (MaxPooling (None, 75, 11, 35, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_11 (Conv3D)           (None, 75, 11, 35, 96)    55392     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 75, 11, 35, 96)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_11 (MaxPooling (None, 75, 5, 17, 96)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 75, 8160)          0         \n",
      "_________________________________________________________________\n",
      "gru_6 (GRU)                  (None, 75, 256)           6465024   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 75, 256)           0         \n",
      "_________________________________________________________________\n",
      "gru_7 (GRU)                  (None, 75, 256)           394752    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 75, 256)           0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 75, 41)            10537     \n",
      "=================================================================\n",
      "Total params: 6,977,801\n",
      "Trainable params: 6,977,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# this part is here to load a partialy trained model. Since it took a long time\n",
    "# i needed to train over multiple sessions. \n",
    "model = load_model('/kaggle/input/final-lip-read/saved-model-v3-45.hdf5',compile=False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T02:50:22.851869Z",
     "iopub.status.busy": "2023-02-18T02:50:22.851538Z",
     "iopub.status.idle": "2023-02-18T02:50:22.859167Z",
     "shell.execute_reply": "2023-02-18T02:50:22.858071Z",
     "shell.execute_reply.started": "2023-02-18T02:50:22.851835Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"model = Sequential()\\nmodel.add(Input(shape=(75,46,140,1)))\\nmodel.add(Conv3D(32,kernel_size = (5,5,1),padding='same'))\\nmodel.add(Activation('relu'))\\nmodel.add(MaxPool3D((1,2,2)))\\n\\nmodel.add(Conv3D(64,kernel_size = (5,5,1),padding='same'))\\nmodel.add(Activation('relu'))\\nmodel.add(MaxPool3D((1,2,2)))\\n\\nmodel.add(Conv3D(96,kernel_size = (3,3,1),padding='same'))\\nmodel.add(Activation('relu'))\\nmodel.add(MaxPool3D((1,2,2)))\\n\\n\\nmodel.add(TimeDistributed(Flatten()))\\nmodel.add(GRU(256,recurrent_initializer='orthogonal',return_sequences=True))\\nmodel.add(Dropout(0.5))\\n\\nmodel.add(GRU(256,recurrent_initializer='orthogonal',return_sequences=True))\\nmodel.add(Dropout(0.5))\\n\\nmodel.add(Dense(characternum.vocabulary_size()+1, kernel_initializer='he_normal', activation='softmax'))\\n\\nmodel.summary()\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is the code for creating the model like the one from the paper\n",
    "'''model = Sequential()\n",
    "model.add(Input(shape=(75,46,140,1)))\n",
    "model.add(Conv3D(32,kernel_size = (5,5,1),padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "model.add(Conv3D(64,kernel_size = (5,5,1),padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "model.add(Conv3D(96,kernel_size = (3,3,1),padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool3D((1,2,2)))\n",
    "\n",
    "\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(GRU(256,recurrent_initializer='orthogonal',return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(GRU(256,recurrent_initializer='orthogonal',return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(characternum.vocabulary_size()+1, kernel_initializer='he_normal', activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T02:50:22.861149Z",
     "iopub.status.busy": "2023-02-18T02:50:22.860816Z",
     "iopub.status.idle": "2023-02-18T02:50:29.753556Z",
     "shell.execute_reply": "2023-02-18T02:50:29.752628Z",
     "shell.execute_reply.started": "2023-02-18T02:50:22.861116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 75, 46, 140, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-18 02:50:25.124814: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 75, 41)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr ,r =data.as_numpy_iterator().next()\n",
    "print(fr.shape)\n",
    "y = model.predict(fr)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T15:30:22.084789Z",
     "iopub.status.busy": "2023-02-14T15:30:22.082680Z",
     "iopub.status.idle": "2023-02-14T15:30:22.101895Z",
     "shell.execute_reply": "2023-02-14T15:30:22.100471Z",
     "shell.execute_reply.started": "2023-02-14T15:30:22.084751Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss=CTCLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T15:30:22.108003Z",
     "iopub.status.busy": "2023-02-14T15:30:22.105814Z",
     "iopub.status.idle": "2023-02-14T15:30:22.114732Z",
     "shell.execute_reply": "2023-02-14T15:30:22.113832Z",
     "shell.execute_reply.started": "2023-02-14T15:30:22.107965Z"
    }
   },
   "outputs": [],
   "source": [
    "filepath = \"saved-model-v3-{epoch:02d}.hdf5\"\n",
    "checkpoint_callback = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=False, mode='min')\n",
    "\n",
    "#checkpoint_callback = ModelCheckpoint(filepath ='my_best_model.hdf5', monitor='loss',save_best_only=False, mode=’min’) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T15:30:22.121173Z",
     "iopub.status.busy": "2023-02-14T15:30:22.119386Z",
     "iopub.status.idle": "2023-02-14T15:30:22.131892Z",
     "shell.execute_reply": "2023-02-14T15:30:22.131006Z",
     "shell.execute_reply.started": "2023-02-14T15:30:22.121138Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T02:54:21.181466Z",
     "iopub.status.busy": "2023-02-18T02:54:21.180580Z",
     "iopub.status.idle": "2023-02-18T02:54:21.188395Z",
     "shell.execute_reply": "2023-02-18T02:54:21.187286Z",
     "shell.execute_reply.started": "2023-02-18T02:54:21.181428Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# this code decodes the predictions for the model. it takes the batch input\n",
    "# it decodes the ctc results and then using a number to character function\n",
    "# takes the number and decodes it to its character and combines all of the \n",
    "# results for the same output\n",
    "def decode_batch_predictions(pred):\n",
    "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
    "    \n",
    "    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0]\n",
    "    # Iterate over the results and get back the text\n",
    "    output_text = []\n",
    "    for result in results:\n",
    "        result = tf.strings.reduce_join(numcharacter(result)).numpy().decode(\"utf-8\")\n",
    "        output_text.append(result)\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T02:50:41.195418Z",
     "iopub.status.busy": "2023-02-18T02:50:41.195045Z",
     "iopub.status.idle": "2023-02-18T02:50:42.577763Z",
     "shell.execute_reply": "2023-02-18T02:50:42.576670Z",
     "shell.execute_reply.started": "2023-02-18T02:50:41.195388Z"
    }
   },
   "outputs": [],
   "source": [
    "fr ,r =data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T02:51:00.040671Z",
     "iopub.status.busy": "2023-02-18T02:51:00.040312Z",
     "iopub.status.idle": "2023-02-18T02:51:00.115769Z",
     "shell.execute_reply": "2023-02-18T02:51:00.114910Z",
     "shell.execute_reply.started": "2023-02-18T02:51:00.040640Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[3.92715505e-04, 7.06533086e-04, 1.54368937e-01, ...,\n",
       "         2.32615207e-07, 1.55888556e-04, 2.01194052e-04],\n",
       "        [1.15997891e-05, 5.15149091e-04, 1.32713700e-04, ...,\n",
       "         6.10261119e-10, 1.64611185e-06, 3.40751831e-05],\n",
       "        [1.51826850e-06, 9.92895305e-01, 1.06430662e-05, ...,\n",
       "         1.36125311e-09, 1.27989244e-06, 1.12719827e-04],\n",
       "        ...,\n",
       "        [9.98312473e-01, 2.01988737e-08, 8.01099560e-08, ...,\n",
       "         3.29071874e-11, 1.67962195e-08, 1.68275111e-03],\n",
       "        [3.36059695e-03, 6.39720099e-08, 1.63123937e-09, ...,\n",
       "         1.48678999e-14, 5.75921311e-10, 9.96638298e-01],\n",
       "        [9.98790205e-01, 1.34166243e-08, 1.05079216e-07, ...,\n",
       "         2.63463071e-11, 2.43913156e-08, 1.20611303e-03]],\n",
       "\n",
       "       [[1.39042968e-04, 1.45364625e-04, 5.68868266e-03, ...,\n",
       "         1.09336282e-08, 1.35872624e-05, 1.79015144e-04],\n",
       "        [2.82467790e-05, 5.76017017e-04, 2.40705976e-05, ...,\n",
       "         5.82730086e-10, 1.19791548e-06, 3.44191387e-04],\n",
       "        [3.62313108e-06, 9.85427797e-01, 4.48850005e-06, ...,\n",
       "         1.99023020e-09, 3.94473363e-06, 1.08293304e-03],\n",
       "        ...,\n",
       "        [9.97384846e-01, 6.01500760e-09, 2.46182665e-08, ...,\n",
       "         6.30592800e-11, 5.21785193e-09, 2.61151395e-03],\n",
       "        [3.41471983e-03, 3.36580328e-08, 6.12290774e-10, ...,\n",
       "         4.63550605e-14, 1.76919548e-10, 9.96584058e-01],\n",
       "        [9.98631775e-01, 5.49922152e-09, 4.70861927e-08, ...,\n",
       "         3.04551731e-11, 9.65684865e-09, 1.36540981e-03]]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = fr\n",
    "output = model.predict(a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## below takes two examples and runs them through the model to see results and decodes the results.\n",
    "\n",
    "## we can see that it does a pretty good job at getting the correct words. It does have some errors. But overall does a good job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-18T02:57:21.034694Z",
     "iopub.status.busy": "2023-02-18T02:57:21.034334Z",
     "iopub.status.idle": "2023-02-18T02:57:21.055406Z",
     "shell.execute_reply": "2023-02-18T02:57:21.054479Z",
     "shell.execute_reply.started": "2023-02-18T02:57:21.034663Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real output: lay red in q six again\n",
      "predicted output lay red in x six again\n",
      "second video\n",
      "real output: lay red with z zero soon\n",
      "predicted output lay red with z zero soon\n"
     ]
    }
   ],
   "source": [
    "print('real output:',tf.strings.reduce_join(numcharacter(r[0])).numpy().decode(\"utf-8\"))\n",
    "print('predicted output',decode_batch_predictions(output)[0])\n",
    "\n",
    "print('second video')\n",
    "print('real output:',tf.strings.reduce_join(numcharacter(r[1])).numpy().decode(\"utf-8\"))\n",
    "print('predicted output',decode_batch_predictions(output)[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
